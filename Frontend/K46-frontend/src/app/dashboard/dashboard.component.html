<div class="dashboard-container" aria-labelledby="projectTitle">
  <h2 id="projectTitle" class="section-title">What’s your Project about?</h2>
  <p class="body-text">
    The introduction of multimodal AI is the next evolution in artificial intelligence whereby models become proficient in processing and interpreting text, images, audio, and visual data simultaneously. Google Gemini and OpenAI GPT-4 are examples of multimodal models that go beyond traditional single-mode AI-alone, specialized-in-one-modality, and provide a more integrated system for instant interpretation of a wide range of data types. So a multimodal AI then could look at an image, process what text is relevant to the picture, and be able to provide informative natural language regarding it — in both of its contexts.
  </p>

  <p class="body-text">
    This innovation has great potential for many applications, from improving accessibility by reading text aloud to the visually impaired or interpreting visual data in healthcare imaging. In customer service, it facilitates the smoothest interactions whereby the users can upload photos or recordings, receiving real-time, context-sensitive assistance. As a result, other companies (e.g., Google and OpenAI) have released multimodal AI platforms that businesses can use to develop custom applications. In a world where AI can work more robustly with complex, multifaceted tasks, multimodal models signal the emergence of an adaptable and multi-talented artificial intelligence that can benefit applications in any industry by increasing productivity levels and flexibility across platforms as well as lending greater accessibility for users through seen language modalities.
  </p>

  <div class="reference-url" aria-label="Reference URL">
    <p><strong>Reference URL:</strong></p>
    <a href="https://techcommunity.microsoft.com/t5/ai-azure-ai-services-blog/azure-ai-vision-at-microsoft-build-2024-multimodal-ai-for/ba-p/4146911" target="_blank" rel="noopener noreferrer" aria-label="Read more about multimodal AI on Microsoft's AI Vision blog">
      https://techcommunity.microsoft.com/t5/ai-azure-ai-services-blog/azure-ai-vision-at-microsoft-build-2024-multimodal-ai-for/ba-p/4146911
    </a>
  </div>
</div>

<div class="dashboard-container" aria-labelledby="techStackTitle">
  <h2 id="techStackTitle" class="section-title">What tech stack did you use?</h2>
  <p>MEAN: MongoDB, Express.js, Angular, and Node.js</p>
  <p class="body-text">
    For my final project, I will be utilizing MongoDB for my database, in addition to using MongoDB Compass to assist me in manipulating my data. To confirm its connection, I have added a script in my server.js file to confirm its connection once I initialize the Node.js server. Therefore, Node.js will be used for the backend. My frontend will be Angular.
  </p>
</div>
